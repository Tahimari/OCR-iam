{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bd26a04e-03ce-46f5-b425-63bf51372ce8",
   "metadata": {},
   "source": [
    "#### Rozpoznawanie tekstu\n",
    "\n",
    "Od zdjęcia do znaków"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4feb875d-d3cb-4ced-b681-116cee777d5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import multiprocessing\n",
    "import os\n",
    "import random\n",
    "import string\n",
    "import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from mxboard import SummaryWriter\n",
    "import mxnet as mx\n",
    "from mxnet import nd, autograd, gluon\n",
    "from mxnet.gluon.model_zoo.vision import resnet34_v1\n",
    "import numpy as np\n",
    "from skimage import transform as skimage_tf\n",
    "from skimage import exposure\n",
    "from tqdm import tqdm\n",
    "np.seterr(all='raise')\n",
    "\n",
    "mx.random.seed(1)\n",
    "\n",
    "from ocr.utils.iam_dataset import IAMDataset\n",
    "from ocr.utils.draw_text_on_image import draw_text_on_image\n",
    "\n",
    "alphabet_encoding = r' !\"#&\\'()*+,-./0123456789:;?ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz'\n",
    "alphabet_dict = {alphabet_encoding[i]:i for i in range(len(alphabet_encoding))}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "187140b7-5d25-4b39-8df0-8a0d0d95b003",
   "metadata": {},
   "source": [
    "#### Definicja sieci\n",
    "Zdefiniuj CNN-biLSTM do rozpoznawania pisma ręcznego.\n",
    "Cechy obrazu na dwóch poziomach zostały uzyskane z obciętego Resnet34 i poddane próbkowaniu w dół za pomocą prostego CNN.\n",
    "Dwa zestawy funkcji obrazu zostały wprowadzone do dwóch oddzielnych funkcji biLSTM do rozpoznawania pisma ręcznego."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7cd6823f-5edb-4aae-82e6-945f5483f747",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLayer(gluon.HybridBlock):\n",
    "    '''\n",
    "    The encoder layer takes the image features from a CNN. The image features are transposed so that the LSTM \n",
    "    slices of the image features can be sequentially fed into the LSTM from left to right (and back via the\n",
    "    bidirectional LSTM). \n",
    "    '''\n",
    "    def __init__(self, hidden_states=200, rnn_layers=1, max_seq_len=100, **kwargs):\n",
    "        self.max_seq_len = max_seq_len\n",
    "        super(EncoderLayer, self).__init__(**kwargs)\n",
    "        with self.name_scope():\n",
    "            self.lstm = mx.gluon.rnn.LSTM(hidden_states, rnn_layers, bidirectional=True)\n",
    "            \n",
    "    def hybrid_forward(self, F, x):\n",
    "        x = x.transpose((0, 3, 1, 2))\n",
    "        x = x.flatten()\n",
    "        x = x.split(num_outputs=self.max_seq_len, axis=1) # (SEQ_LEN, N, CHANNELS)\n",
    "        x = F.concat(*[elem.expand_dims(axis=0) for elem in x], dim=0)\n",
    "        x = self.lstm(x)\n",
    "        x = x.transpose((1, 0, 2)) #(N, SEQ_LEN, HIDDEN_UNITS)\n",
    "        return x\n",
    "\n",
    "class CNNBiLSTM(gluon.HybridBlock):\n",
    "    '''\n",
    "    The CNN-biLSTM to recognise handwriting text given an image of handwriten text.\n",
    "    Parameters\n",
    "    ----------\n",
    "    num_downsamples: int, default 2\n",
    "        The number of times to downsample the image features. Each time the features are downsampled, a new LSTM\n",
    "        is created. \n",
    "    resnet_layer_id: int, default 4\n",
    "        The layer ID to obtain features from the resnet34\n",
    "    lstm_hidden_states: int, default 200\n",
    "        The number of hidden states used in the LSTMs\n",
    "    lstm_layers: int, default 1\n",
    "        The number of layers of LSTMs to use\n",
    "    '''\n",
    "    FEATURE_EXTRACTOR_FILTER = 64\n",
    "    def __init__(self, num_downsamples=2, resnet_layer_id=4, rnn_hidden_states=200, rnn_layers=1, max_seq_len=100, ctx=mx.gpu(0), **kwargs):\n",
    "        super(CNNBiLSTM, self).__init__(**kwargs)\n",
    "        self.p_dropout = 0.5\n",
    "        self.num_downsamples = num_downsamples\n",
    "        self.max_seq_len = max_seq_len\n",
    "        self.ctx = ctx\n",
    "        with self.name_scope():\n",
    "            self.body = self.get_body(resnet_layer_id=resnet_layer_id)\n",
    "\n",
    "            self.encoders = gluon.nn.HybridSequential()\n",
    "            with self.encoders.name_scope():\n",
    "                for i in range(self.num_downsamples):\n",
    "                    encoder = self.get_encoder(rnn_hidden_states=rnn_hidden_states, rnn_layers=rnn_layers, max_seq_len=max_seq_len)\n",
    "                    self.encoders.add(encoder)\n",
    "            self.decoder = self.get_decoder()\n",
    "            self.downsampler = self.get_down_sampler(self.FEATURE_EXTRACTOR_FILTER)\n",
    "\n",
    "    def get_down_sampler(self, num_filters):\n",
    "        '''\n",
    "        Creates a two-stacked Conv-BatchNorm-Relu and then a pooling layer to\n",
    "        downsample the image features by half.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        num_filters: int\n",
    "            To select the number of filters in used the downsampling convolutional layer.\n",
    "        Returns\n",
    "        -------\n",
    "        network: gluon.nn.HybridSequential\n",
    "            The downsampler network that decreases the width and height of the image features by half.\n",
    "        \n",
    "        '''\n",
    "        out = gluon.nn.HybridSequential()\n",
    "        with out.name_scope():\n",
    "            for _ in range(2):\n",
    "                out.add(gluon.nn.Conv2D(num_filters, 3, strides=1, padding=1))\n",
    "                out.add(gluon.nn.BatchNorm(in_channels=num_filters))\n",
    "                out.add(gluon.nn.Activation('relu'))\n",
    "            out.add(gluon.nn.MaxPool2D(2))\n",
    "            out.collect_params().initialize(mx.init.Normal(), ctx=self.ctx)\n",
    "        out.hybridize()\n",
    "        return out\n",
    "\n",
    "    def get_body(self, resnet_layer_id):\n",
    "        '''\n",
    "        Create the feature extraction network based on resnet34.\n",
    "        The first layer of the res-net is converted into grayscale by averaging the weights of the 3 channels\n",
    "        of the original resnet.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        resnet_layer_id: int\n",
    "            The resnet_layer_id specifies which layer to take from \n",
    "            the bottom of the network.\n",
    "        Returns\n",
    "        -------\n",
    "        network: gluon.nn.HybridSequential\n",
    "            The body network for feature extraction based on resnet\n",
    "        '''\n",
    "        \n",
    "        pretrained = resnet34_v1(pretrained=True, ctx=self.ctx)\n",
    "        pretrained_2 = resnet34_v1(pretrained=True, ctx=mx.cpu(0))\n",
    "        first_weights = pretrained_2.features[0].weight.data().mean(axis=1).expand_dims(axis=1)\n",
    "        # First weights could be replaced with individual channels.\n",
    "        \n",
    "        body = gluon.nn.HybridSequential()\n",
    "        with body.name_scope():\n",
    "            first_layer = gluon.nn.Conv2D(channels=64, kernel_size=(7, 7), padding=(3, 3), strides=(2, 2), in_channels=1, use_bias=False)\n",
    "            first_layer.initialize(mx.init.Xavier(), ctx=self.ctx)\n",
    "            first_layer.weight.set_data(first_weights)\n",
    "            body.add(first_layer)\n",
    "            body.add(*pretrained.features[1:-resnet_layer_id])\n",
    "        return body\n",
    "\n",
    "    def get_encoder(self, rnn_hidden_states, rnn_layers, max_seq_len):\n",
    "        '''\n",
    "        Creates an LSTM to learn the sequential component of the image features.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        \n",
    "        rnn_hidden_states: int\n",
    "            The number of hidden states in the RNN\n",
    "        \n",
    "        rnn_layers: int\n",
    "            The number of layers to stack the RNN\n",
    "        Returns\n",
    "        -------\n",
    "        \n",
    "        network: gluon.nn.Sequential\n",
    "            The encoder network to learn the sequential information of the image features\n",
    "        '''\n",
    "\n",
    "        encoder = gluon.nn.HybridSequential()\n",
    "        with encoder.name_scope():\n",
    "            encoder.add(EncoderLayer(hidden_states=rnn_hidden_states, rnn_layers=rnn_layers, max_seq_len=max_seq_len))\n",
    "            encoder.add(gluon.nn.Dropout(self.p_dropout))\n",
    "        encoder.collect_params().initialize(mx.init.Xavier(), ctx=self.ctx)\n",
    "        return encoder\n",
    "    \n",
    "    def get_decoder(self):\n",
    "        '''\n",
    "        Creates a network to convert the output of the encoder into characters.\n",
    "        '''\n",
    "\n",
    "        alphabet_size = len(alphabet_encoding) + 1\n",
    "        decoder = mx.gluon.nn.Dense(units=alphabet_size, flatten=False)\n",
    "        decoder.collect_params().initialize(mx.init.Xavier(), ctx=self.ctx)\n",
    "        return decoder\n",
    "\n",
    "    def hybrid_forward(self, F, x):\n",
    "        features = self.body(x)\n",
    "        hidden_states = []\n",
    "        hs = self.encoders[0](features)\n",
    "        hidden_states.append(hs)\n",
    "        for i, _ in enumerate(range(self.num_downsamples - 1)):\n",
    "            features = self.downsampler(features)\n",
    "            hs = self.encoders[i+1](features)\n",
    "            hidden_states.append(hs)\n",
    "        hs = F.concat(*hidden_states, dim=2)\n",
    "        output = self.decoder(hs)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4610bfbf-a6a4-4e56-8694-43ea4c90d1e5",
   "metadata": {},
   "source": [
    "#### Funkcja pomocnicza do trenowania sieci"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0718591d-c326-424b-a5b1-56d5ec2740de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform(image, label):\n",
    "    '''\n",
    "    This function resizes the input image and converts so that it could be fed into the network.\n",
    "    Furthermore, the label (text) is one-hot encoded.\n",
    "    '''\n",
    "    image = np.expand_dims(image, axis=0).astype(np.float32)\n",
    "    if image[0, 0, 0] > 1:\n",
    "        image = image/255.\n",
    "    image = (image - 0.942532484060557) / 0.15926149044640417\n",
    "    label_encoded = np.zeros(max_seq_len, dtype=np.float32)-1\n",
    "    i = 0\n",
    "    for word in label:\n",
    "        word = word.replace(\"&quot\", r'\"')\n",
    "        word = word.replace(\"&amp\", r'&')\n",
    "        word = word.replace('\";', '\\\"')\n",
    "        for letter in word:\n",
    "            label_encoded[i] = alphabet_dict[letter]\n",
    "            i += 1\n",
    "    return image, label_encoded\n",
    "\n",
    "def augment_transform(image, label):\n",
    "    '''\n",
    "    This function randomly:\n",
    "        - translates the input image by +-width_range and +-height_range (percentage).\n",
    "        - scales the image by y_scaling and x_scaling (percentage)\n",
    "        - shears the image by shearing_factor (radians)\n",
    "    '''\n",
    "    \n",
    "    ty = random.uniform(-random_y_translation, random_y_translation)\n",
    "    tx = random.uniform(-random_x_translation, random_x_translation)\n",
    "\n",
    "    sx = random.uniform(1. - random_y_scaling, 1. + random_y_scaling)\n",
    "    sy = random.uniform(1. - random_x_scaling, 1. + random_x_scaling)\n",
    "\n",
    "    s = random.uniform(-random_shearing, random_shearing)\n",
    "    \n",
    "    gamma = random.uniform(0.001, 2)\n",
    "    image = exposure.adjust_gamma(image, gamma)\n",
    "    st = skimage_tf.AffineTransform(scale=(sx, sy),\n",
    "                                    shear=s,\n",
    "                                    translation=(tx*image.shape[1], ty*image.shape[0]))\n",
    "    augmented_image = skimage_tf.warp(image, st, cval=1.0)\n",
    "    \n",
    "    return transform(augmented_image*255., label)\n",
    "\n",
    "\n",
    "def decode(prediction):\n",
    "    '''\n",
    "    Returns the string given one-hot encoded vectors.\n",
    "    '''\n",
    "\n",
    "    results = []\n",
    "    for word in prediction:\n",
    "        result = []\n",
    "        for i, index in enumerate(word):\n",
    "            if i < len(word) - 1 and word[i] == word[i+1] and word[-1] != -1: #Hack to decode label as well\n",
    "                continue\n",
    "            if index == len(alphabet_dict) or index == -1:\n",
    "                continue\n",
    "            else:\n",
    "                result.append(alphabet_encoding[int(index)])\n",
    "        results.append(result)\n",
    "    words = [''.join(word) for word in results]\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2c427a90-13ed-4421-9ffe-c2e36f3b3a1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_epoch(e, network, dataloader, trainer, log_dir, print_name, is_train):\n",
    "    total_loss = nd.zeros(1, ctx)\n",
    "    for i, (x, y) in enumerate(dataloader):\n",
    "        x = x.as_in_context(ctx)\n",
    "        y = y.as_in_context(ctx)\n",
    "\n",
    "        with autograd.record(train_mode=is_train):\n",
    "            output = network(x)\n",
    "            loss_ctc = ctc_loss(output, y)\n",
    "\n",
    "        if is_train:\n",
    "            loss_ctc.backward()\n",
    "            trainer.step(x.shape[0])\n",
    "\n",
    "        if i == 0 and e % send_image_every_n == 0 and e > 0:\n",
    "            predictions = output.softmax().topk(axis=2).asnumpy()\n",
    "            decoded_text = decode(predictions)\n",
    "            output_image = draw_text_on_image(x.asnumpy(), decoded_text)\n",
    "            output_image[output_image < 0] = 0\n",
    "            output_image[output_image > 1] = 1\n",
    "            print(\"{} first decoded text = {}\".format(print_name, decoded_text[0]))\n",
    "            with SummaryWriter(logdir=log_dir, verbose=False, flush_secs=5) as sw:\n",
    "                sw.add_image('bb_{}_image'.format(print_name), output_image, global_step=e)\n",
    "\n",
    "        total_loss += loss_ctc.mean()\n",
    "\n",
    "    epoch_loss = float(total_loss.asscalar())/len(dataloader)\n",
    "\n",
    "    with SummaryWriter(logdir=log_dir, verbose=False, flush_secs=5) as sw:\n",
    "        sw.add_scalar('loss', {print_name: epoch_loss}, global_step=e)\n",
    "\n",
    "    return epoch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cd219436-7e59-49d5-943a-cf28df2ea04e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ctx = mx.gpu()\n",
    "\n",
    "epochs = 120\n",
    "learning_rate = 0.0001\n",
    "batch_size = 32\n",
    "\n",
    "max_seq_len = 160\n",
    "print_every_n = 5\n",
    "send_image_every_n = 5\n",
    "\n",
    "num_downsamples = 2\n",
    "resnet_layer_id = 4\n",
    "lstm_hidden_states = 512\n",
    "lstm_layers = 2\n",
    "\n",
    "random_y_translation, random_x_translation = 0.03, 0.03\n",
    "random_y_scaling, random_x_scaling = 0.1, 0.1\n",
    "random_shearing = 0.7\n",
    "\n",
    "log_dir = \"./logs/handwriting_recognition\"\n",
    "checkpoint_dir = \"model_checkpoint\"\n",
    "checkpoint_name = \"handwriting.params\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0c6cee69-0d74-4dad-be5e-1415b7fe8466",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training samples: 7998\n",
      "Number of testing samples: 1860\n"
     ]
    }
   ],
   "source": [
    "train_ds = IAMDataset(\"line\", output_data=\"text\", train=True)\n",
    "print(\"Number of training samples: {}\".format(len(train_ds)))\n",
    "\n",
    "test_ds = IAMDataset(\"line\", output_data=\"text\", train=False)\n",
    "print(\"Number of testing samples: {}\".format(len(test_ds)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "96c6b0a2-583a-46bb-be25-bdb4e7405a87",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = gluon.data.DataLoader(train_ds.transform(augment_transform), batch_size, shuffle=True, last_batch=\"rollover\", num_workers=4)\n",
    "test_data = gluon.data.DataLoader(test_ds.transform(transform), batch_size, shuffle=True, last_batch=\"keep\", num_workers=4)#, num_workers=multiprocessing.cpu_count()-2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "663d6d2d-bd9e-4c68-b554-973c7b052125",
   "metadata": {},
   "source": [
    "#### Trenowanie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "237b0027-bdf6-4447-af54-67187f362965",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = CNNBiLSTM(num_downsamples=num_downsamples, resnet_layer_id=resnet_layer_id , rnn_hidden_states=lstm_hidden_states, rnn_layers=lstm_layers, max_seq_len=max_seq_len, ctx=ctx)\n",
    "net.hybridize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "73a34f3b-6999-4aec-a03d-72738bc12ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "ctc_loss = gluon.loss.CTCLoss(weight=0.2)\n",
    "best_test_loss = 10e5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "30bc6244-a457-4cd1-8cf0-4878c07697b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "if (os.path.isfile(os.path.join(checkpoint_dir, checkpoint_name))):\n",
    "    net.load_parameters(os.path.join(checkpoint_dir, checkpoint_name))\n",
    "    print(\"Parameters loaded\")\n",
    "    print(run_epoch(0, net, test_data, None, log_dir, print_name=\"pretrained\", is_train=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "86250d13-a8dd-4dce-8717-483a98eb6881",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters loaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[10:02:26] ../src/operator/nn/./cudnn/./cudnn_algoreg-inl.h:97: Running performance tests to find the best convolution algorithm, this can take a while... (set the environment variable MXNET_CUDNN_AUTOTUNE_DEFAULT to 0 to disable)\n"
     ]
    },
    {
     "ename": "MXNetError",
     "evalue": "Traceback (most recent call last):\n  File \"../src/storage/./pooled_storage_manager.h\", line 161\nMXNetError: cudaMalloc retry failed: out of memory",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMXNetError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_29853/3399965614.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_parameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpretrained\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Parameters loaded\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprint_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"pretrained\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_train\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_29853/3067181571.py\u001b[0m in \u001b[0;36mrun_epoch\u001b[0;34m(e, network, dataloader, trainer, log_dir, print_name, is_train)\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0mtotal_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss_ctc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m     \u001b[0mepoch_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masscalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mSummaryWriter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogdir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlog_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflush_secs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msw\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/handwritten-text-recognition-for-apache-mxnet/lib/python3.8/site-packages/mxnet/ndarray/ndarray.py\u001b[0m in \u001b[0;36masscalar\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2583\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"The current array is not a scalar\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2584\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2585\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2586\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2587\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/handwritten-text-recognition-for-apache-mxnet/lib/python3.8/site-packages/mxnet/ndarray/ndarray.py\u001b[0m in \u001b[0;36masnumpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2561\u001b[0m         \"\"\"\n\u001b[1;32m   2562\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2563\u001b[0;31m         check_call(_LIB.MXNDArraySyncCopyToCPU(\n\u001b[0m\u001b[1;32m   2564\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2565\u001b[0m             \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_as\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_void_p\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/handwritten-text-recognition-for-apache-mxnet/lib/python3.8/site-packages/mxnet/base.py\u001b[0m in \u001b[0;36mcheck_call\u001b[0;34m(ret)\u001b[0m\n\u001b[1;32m    244\u001b[0m     \"\"\"\n\u001b[1;32m    245\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 246\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mget_last_ffi_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    247\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    248\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mMXNetError\u001b[0m: Traceback (most recent call last):\n  File \"../src/storage/./pooled_storage_manager.h\", line 161\nMXNetError: cudaMalloc retry failed: out of memory"
     ]
    }
   ],
   "source": [
    "pretrained = \"models/handwriting_line8.params\"\n",
    "if (os.path.isfile(pretrained)):\n",
    "    net.load_parameters(pretrained, ctx=ctx)\n",
    "    print(\"Parameters loaded\")\n",
    "    print(run_epoch(0, net, test_data, None, log_dir, print_name=\"pretrained\", is_train=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "03b0939d-f52b-48e5-b1be-2db11deb8b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = gluon.Trainer(net.collect_params(), 'adam', {'learning_rate': learning_rate})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "42951a03-9c41-4b22-a25d-bcfda0cd7d8f",
   "metadata": {},
   "outputs": [
    {
     "ename": "MXNetError",
     "evalue": "Traceback (most recent call last):\n  File \"../src/storage/./pooled_storage_manager.h\", line 161\nMXNetError: cudaMalloc retry failed: out of memory",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMXNetError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_29853/4111805581.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0me\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprint_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"train\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_train\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mtest_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprint_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"test\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_train\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtest_loss\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mbest_test_loss\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Saving network, previous best test loss {:.6f}, current test loss {:.6f}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbest_test_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_29853/3067181571.py\u001b[0m in \u001b[0;36mrun_epoch\u001b[0;34m(e, network, dataloader, trainer, log_dir, print_name, is_train)\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0mtotal_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss_ctc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m     \u001b[0mepoch_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masscalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mSummaryWriter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogdir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlog_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflush_secs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msw\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/handwritten-text-recognition-for-apache-mxnet/lib/python3.8/site-packages/mxnet/ndarray/ndarray.py\u001b[0m in \u001b[0;36masscalar\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2583\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"The current array is not a scalar\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2584\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2585\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2586\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2587\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/handwritten-text-recognition-for-apache-mxnet/lib/python3.8/site-packages/mxnet/ndarray/ndarray.py\u001b[0m in \u001b[0;36masnumpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2561\u001b[0m         \"\"\"\n\u001b[1;32m   2562\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2563\u001b[0;31m         check_call(_LIB.MXNDArraySyncCopyToCPU(\n\u001b[0m\u001b[1;32m   2564\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2565\u001b[0m             \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_as\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_void_p\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/handwritten-text-recognition-for-apache-mxnet/lib/python3.8/site-packages/mxnet/base.py\u001b[0m in \u001b[0;36mcheck_call\u001b[0;34m(ret)\u001b[0m\n\u001b[1;32m    244\u001b[0m     \"\"\"\n\u001b[1;32m    245\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 246\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mget_last_ffi_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    247\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    248\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mMXNetError\u001b[0m: Traceback (most recent call last):\n  File \"../src/storage/./pooled_storage_manager.h\", line 161\nMXNetError: cudaMalloc retry failed: out of memory"
     ]
    }
   ],
   "source": [
    "for e in range(epochs):\n",
    "    train_loss = run_epoch(e, net, train_data, trainer, log_dir, print_name=\"train\", is_train=True)\n",
    "    test_loss = run_epoch(e, net, test_data, trainer, log_dir, print_name=\"test\", is_train=False)    \n",
    "    if test_loss < best_test_loss:\n",
    "        print(\"Saving network, previous best test loss {:.6f}, current test loss {:.6f}\".format(best_test_loss, test_loss))\n",
    "        net.save_parameters(os.path.join(checkpoint_dir, checkpoint_name))\n",
    "        best_test_loss = test_loss\n",
    "        \n",
    "    if e % print_every_n == 0 and e > 0:\n",
    "        print(\"Epoch {0}, train_loss {1:.6f}, test_loss {2:.6f}\".format(e, train_loss, test_loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38e870a9-9337-4b05-a62a-7cbe118fa0d4",
   "metadata": {},
   "source": [
    "#### Wyniki\n",
    "Wizualnie sprawdź wyniki zestawu danych testowych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "673d3d2a-840b-47ed-b12b-b343077e795f",
   "metadata": {},
   "outputs": [
    {
     "ename": "MXNetError",
     "evalue": "Traceback (most recent call last):\n  File \"../src/storage/./pooled_storage_manager.h\", line 161\nMXNetError: cudaMalloc retry failed: out of memory",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMXNetError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_29853/2603784401.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtopk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0mdecoded_prediction_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"&quot\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'\\\"'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"&amp\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"&\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\";'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'\\\"'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0maxs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Greys_r'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/handwritten-text-recognition-for-apache-mxnet/lib/python3.8/site-packages/mxnet/ndarray/ndarray.py\u001b[0m in \u001b[0;36masnumpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2561\u001b[0m         \"\"\"\n\u001b[1;32m   2562\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2563\u001b[0;31m         check_call(_LIB.MXNDArraySyncCopyToCPU(\n\u001b[0m\u001b[1;32m   2564\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2565\u001b[0m             \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_as\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_void_p\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/handwritten-text-recognition-for-apache-mxnet/lib/python3.8/site-packages/mxnet/base.py\u001b[0m in \u001b[0;36mcheck_call\u001b[0;34m(ret)\u001b[0m\n\u001b[1;32m    244\u001b[0m     \"\"\"\n\u001b[1;32m    245\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 246\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mget_last_ffi_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    247\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    248\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mMXNetError\u001b[0m: Traceback (most recent call last):\n  File \"../src/storage/./pooled_storage_manager.h\", line 161\nMXNetError: cudaMalloc retry failed: out of memory"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x936 with 10 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "figs_to_plot = 10\n",
    "fig, axs = plt.subplots(figs_to_plot, figsize=(8, 1.3*figs_to_plot))\n",
    "\n",
    "for i in range(figs_to_plot):\n",
    "    n = int(random.random()*len(test_ds))\n",
    "    image, actual_label = test_ds[n]\n",
    "    image, _ = transform(image, actual_label)\n",
    "\n",
    "    image = nd.array(image)\n",
    "    image = image.as_in_context(ctx)\n",
    "    image = image.expand_dims(axis=0)\n",
    "    output = net(image)\n",
    "    predictions = output.softmax().topk(axis=2).asnumpy()\n",
    "    decoded_prediction_text = decode(predictions)[0].replace(\"&quot\", '\\\"').replace(\"&amp\", \"&\").replace('\";', '\\\"')\n",
    "    axs[i].imshow(image.asnumpy().squeeze(), cmap='Greys_r')\n",
    "    axs[i].set_title(\"[Label]: {}\\n[Pred]:  {}\".format(actual_label[0].replace(\"&quot\", '\\\"').replace(\"&amp\", \"&\").replace('\";', '\\\"'), decoded_prediction_text),\n",
    "                    fontdict={\"horizontalalignment\":\"left\", \"family\":\"monospace\"}, x=0)\n",
    "    axs[i].tick_params(axis='both',       \n",
    "                       which='both',      \n",
    "                       bottom=False,      \n",
    "                       top=False,         \n",
    "                       left=False,\n",
    "                       right=False,\n",
    "                       labelleft=False,\n",
    "                       labelbottom=False) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fba5e1db-b70a-436a-882a-41e5a9fca4b9",
   "metadata": {},
   "source": [
    "#### Pisanie przekształconego testowego zestawu danych w celu sprawdzenia odszumiania języka"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b750762c-eb66-4f29-9c1d-057b78e52b6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_lm = test_ds.transform(transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "646e0cd2-cb9c-4e47-9620-db7dcd3d7519",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                            | 0/1860 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "MXNetError",
     "evalue": "Traceback (most recent call last):\n  File \"../src/storage/./pooled_storage_manager.h\", line 161\nMXNetError: cudaMalloc retry failed: out of memory",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMXNetError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_29853/3668701054.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtopk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mdecoded_prediction_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mactual_label\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"&quot;\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'\"'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"&amp;\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"&\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoded_prediction_text\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"&quot\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'\\\"'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"&amp\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"&\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\";'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'\\\"'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/handwritten-text-recognition-for-apache-mxnet/lib/python3.8/site-packages/mxnet/ndarray/ndarray.py\u001b[0m in \u001b[0;36masnumpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2561\u001b[0m         \"\"\"\n\u001b[1;32m   2562\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2563\u001b[0;31m         check_call(_LIB.MXNDArraySyncCopyToCPU(\n\u001b[0m\u001b[1;32m   2564\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2565\u001b[0m             \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_as\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_void_p\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/handwritten-text-recognition-for-apache-mxnet/lib/python3.8/site-packages/mxnet/base.py\u001b[0m in \u001b[0;36mcheck_call\u001b[0;34m(ret)\u001b[0m\n\u001b[1;32m    244\u001b[0m     \"\"\"\n\u001b[1;32m    245\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 246\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mget_last_ffi_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    247\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    248\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mMXNetError\u001b[0m: Traceback (most recent call last):\n  File \"../src/storage/./pooled_storage_manager.h\", line 161\nMXNetError: cudaMalloc retry failed: out of memory"
     ]
    }
   ],
   "source": [
    "outputs = []\n",
    "for image, actual_label in tqdm(ds_lm):\n",
    "    image = nd.array(image)\n",
    "    image = image.as_in_context(ctx)\n",
    "    image = image.expand_dims(axis=0)\n",
    "    output = net(image)\n",
    "    predictions = output.softmax().topk(axis=2).asnumpy()\n",
    "    decoded_prediction_text = decode(predictions)[0]\n",
    "    outputs.append([decode([actual_label])[0].replace(\"&quot;\", '\"').replace(\"&amp;\", \"&\"), decoded_prediction_text.replace(\"&quot\", '\\\"').replace(\"&amp\", \"&\").replace('\";', '\\\"')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d40a9103-9a36-4344-ad03-b07c2f74510d",
   "metadata": {},
   "outputs": [],
   "source": [
    "json.dump(outputs, open('dataset/typo/validating.json', 'w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f2ed956-bf53-4f93-aaba-5f82c31af75e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_lm = train_ds\n",
    "with open('dataset/typo/text_train.txt', 'w') as f:\n",
    "    for _, actual_label in ds_lm:\n",
    "        f.write(str(actual_label[0].replace(\"&quot;\", '\"').replace(\"&amp;\", \"&\"))+\"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "OCR-iam",
   "language": "python",
   "name": "ocr-iam"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
